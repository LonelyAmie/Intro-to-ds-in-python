- def : to **Split** a DataFrame into pieces and do some manipulations
- a common `.groupby()` pattern is called *Split-Apply-Combine*

# Split (main form) : 

```python
df.groupby(by= ... ) # Returns a groupby object
```
you can give a string, a list or a UDF.
- String : the given string must be a column name to group by.
	```python
	df.groupby('Age')
	```
- Multi-indexing
	 1.  List : the list can act as a multi-index or it can contain other objects too
	```python
	df.groupby(['Age', 'Score']) # Returns a multi-index groupby object
	```
	2.  Passing a multi-index DataFrame
	```python
	df.set_index(['Age', 'Score'], inplace=True)	
	
	df.groupby(level = ['Age']) # Only groups by the Age index
	"as if it's reindexing with 'Age'"
	df.groupby(level = ['Score']) # Only groups by the Score index
	"as if it's reindexing with 'Score'"
	df.groupby(level = ['Age', 'Score']) # groups by both indeex
	"as if it's reindexing with 'Age' and 'Score'"
	```


- UDF : the function should act as a Dict which returns certain values for given conditions and the return values act as the keys for the groupby object
	> [!Hint] Disclaimer
	> if no column is specified for groupby() it will automatically use the __index__ (or __multi-index__ as a tuple)
	> so for using it, a common approach to use (func + column) is to do this :
	> `df.set_index('column1)'`
	> `df.groupby(func)` 
	`df.reset_index()`


	```python
	def set_age_num (item) : 
		if item > 5 : 
		return 1
		if item == 5 : 
		return 0
		else :
		return -1
	df.set_index('age', inplace=True)
	df.groupby(set_age_num)
	df.reset_index()
	```
---
# Apply 
1. `.agg()`

- ## Basic use case 
	```python
	grouped = df.groupby('State_name')
	# i want the maximum value of the Column 'Temp' for each state name
	grouped.agg(
				max_temp = (Column = 'Temp', aggfunc = np.nanmean)
				)
	```
- ## A Bit more advanced usage 
	1. Aggregating on different columns 
		```python
		# I want to use functions on different Columns of the Dataframe df
		grouped.agg(
		max_tmp = ('Temp', np.nanmax) 
		avg_cost = (Column ='Monthly_cost', aggfunc = np.nanmean)
		min_rent = (Column = 'house_rent', aggfunc = np.nanmin)
		)
		```
	2. Aggregating on the same column
	```python
	# I want to use different functions on the same column
	grouped['Temp'].agg([np.nanmean, np.nanmax, np.nanmin])
	# OR
	grouped['Temp'].agg(my_mean = np.nanmean
						my_max = np.nanmax
						my_min = np.nanmin
						)
	```
	3. Final Form (==Approved==) 
	```python
	# Passing a dict of List
	my_dict = {'house_rent' : [np.nanmean, 'np.nanmax'],
			   'Temp' : [np.nanmin, np.nanstd]}
	grouped.agg(my_dict)
	# Applies the np.nanmean and np.nanmax to the column 'house_rent'
	# and applies np.min and np.nanstd to the column 'Temp'
	```

> [!caution] Caution 
> passing a dict-of-dict is deprecated and shouldn't be used
> ```python
> df.groupby('A').agg({'B': {'foo': 'sum'}, 'C': {'bar': 'min'}})
> ```

---
2. .`transform()`
	## Key points 
	-  works __column by column__ -> when working with UDFs, each column for each group is passed to the function
	- output of UDF must be either __Scalar object__ to be broadcasted to all cells
		or it must a __sequence__ with the same lenght as the passed column
		
	- for more info, visit this [page](https://stackoverflow.com/questions/27517425/apply-vs-transform-on-a-group-object)
	- returns a DataFrame (not a groupby object) with the same indexes as the original DataFrame being grouped => can be used for [[7. Merging]] on indexes.
	## Basic use case 
	```python
		df = pd.DataFrame({'State':['Texas', 'Texas', 'Florida', 'Florida','Washington'],
				   'a':[4,5,1,3,2], 'b':[6,10,3,11,12]})

	df['my_mean'] = df.groupby('STATE')['a'].transform('mean') 
# Makes a new column with same indexes and fill each cell with the 
# mean of column 'a'

	df['my_sum'] = df.groupby('STATE')['b'].transform('sum')
# Makes a new column with same indexes and fill each cell with the 
# sum of column 'b'
```

> [!Tip] Import thing to remember while using `.transform()` is to pass only ___1 column___ to the method.
> if you want to work with multiple columns, either :
> 1. use `.apply()` 
> 2. use ___chaining functions___ + `.transform()` to achieve your goal.
>

> [!Hint] Remember not to mutate the original DataFrame while iterating over it
> ```python
> grouped = df.groupby('Grade')
> result = df.copy()
> result['new column'] = grouped.transform('cumsum')
> ```
## Merging on same indexes 
```python 
cols = ['name', 'family', 'age', 'grade']
transformed_df = df[cols].groupby('age')['grade'].transform(np.nanmean)
df = df.merge(transformed_df, left_index = True, right_index = True)
```
---
3. `.filter()`
	- used when the purpose is to select a subset of the original DataFrame
	## Basic use case 
	It is usually used when (DataFrame is grouped by `Column A`) you want a aggregating `function`  to be applied on each group separately and select those groups whose returned value satisfies a condition

  - Example 
  ```python
  df = pd.readcsv('resturant_receit.csv')
  # Question :
  #Which meals were eaten on days where the average bill was greater than                                    20?

  df.groupby('day').filter(lambda x : x['cost'].mean() > 20)
  ```
  - using `.filter()`, a group is either accepted completely or nothing at all. it is not possible to accept some parts a group and not accept the rest
  - Example 
  > We could for example filter for all sales reps who have at least made 200k

```python
df = pd.read_csv()
df.groupby('sales_rep').filter(

lambda x : (x.['num'] * x.['price']).sum() > 200k
							   )
```
> [!Important] Important 
> it’s important to know that GroupBy allows you to apply the filtering method based on __aggregations__ of groups’ values. 

---
3. `.apply()` 
	- using apply function with an arbitrary function. 
	- for more info --> [[6. Some new functions]]
	- usually slower that using specialized functions like `.agg()`, but it's a useful 